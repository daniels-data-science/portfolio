{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e44fd5a6-3d46-41ee-a74e-29132d6458f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Transformer-based English to Russian AI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c188065f-2a60-45ad-9f0f-e62487c04278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0 [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re\n",
    "import warnings\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "print(\n",
    "    tf.__version__, \n",
    "    tf.config.list_physical_devices('GPU') # GPU required for this task\n",
    ")\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd57255-ba9f-4183-be39-108f6b27f901",
   "metadata": {},
   "source": [
    "We will be using a text file provided by [Anki's Russian-English biligual sentence pairs](http://www.manythings.org/anki/) for this project. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0796632-9ae8-4997-879d-cb42bfdf119d",
   "metadata": {},
   "source": [
    "## **Data Preprocessings**\n",
    "#### 1. Add `\"[start]\"` and `\"[end]\"` tokens to the Russian text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06e20447-ca23-49c2-af83-dd33a0d01ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bilingual_file_dir = \"rus.txt\"\n",
    "# this is a csv file containing English in the first column and Russian in the second\n",
    "\n",
    "with open(bilingual_file_dir, encoding='utf-8') as f: \n",
    "    lines = f.read().split(\"\\n\")\n",
    "text_pairs = []        \n",
    "for line in lines:\n",
    "    english, russian, _ = line.split(\"\\t\")\n",
    "    russian = \"[start] \" + russian + \" [end]\"\n",
    "    text_pairs.append((english, russian))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf05867-7b8a-4346-8b69-3d0fa6399286",
   "metadata": {},
   "source": [
    "#### 2. Split the paired data into train/val/test groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0952c28b-d888-4138-815e-ae09d26c085b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(text_pairs))\n",
    "random.shuffle(text_pairs)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f78ebd6-f575-4c32-baf5-ec0b9ca5d297",
   "metadata": {},
   "source": [
    "#### 3. Set tokenisation parameters\n",
    "* `vocab_size`: the top *n* most frequent tokens in the training texts for both languages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d36335-152d-40bd-8872-995a7829c123",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 15_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6282de-e252-43de-b544-b50f6bd94201",
   "metadata": {},
   "source": [
    "* `sequence_length`: both english and russian sentences do not exceed this many words. Words after this cap will be cut off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e681090-0e5e-4c84-ae78-6e5e3a4657f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea155d41-4e8e-4915-8806-ac517ef64f39",
   "metadata": {},
   "source": [
    "* `embed_dim`: Each embedded token is a vector of this length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2aa4cb-ad3f-4e79-90e7-c74e8beeb1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a640d3-b57b-4e5c-8edd-0d56761218c0",
   "metadata": {},
   "source": [
    "#### 4. Standardise sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6afd986-b5a6-4a2c-bee0-f71a71b72968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(string):\n",
    "    strip_chars = '\"#$%&\\'()*+,-./:;<=>@\\\\^_`{|}~â€”'\n",
    "    \n",
    "    string = tf.strings.lower(string)\n",
    "    \n",
    "    string = tf.strings.regex_replace(string, f\"[{re.escape(strip_chars)}]\", \"\")\n",
    "    # Remove characters in strip_chars using regular expression\n",
    "    return string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e711a46-1b38-426f-bfd5-50ab280a7fec",
   "metadata": {},
   "source": [
    "#### 5. Index each word to build a vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2bf44584-14a7-4bff-87a6-b18bce4e90af",
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_vectorization = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    "    standardize=standardize\n",
    ")\n",
    "rus_vectorization = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1, # needs to be one step ahead\n",
    "    standardize=standardize\n",
    ")\n",
    "\n",
    "train_english_texts = [pair[0] for pair in train_pairs]\n",
    "train_russian_texts = [pair[1] for pair in train_pairs]\n",
    "\n",
    "# the .adapt() method builds the vocabulary from input data\n",
    "eng_vectorization.adapt(train_english_texts)\n",
    "rus_vectorization.adapt(train_russian_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9be256b3-20fd-4fcc-8fd8-22d0dfd0934e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256 \n",
    "\n",
    "def format_dataset(eng, rus):\n",
    "    eng = eng_vectorization(eng)\n",
    "    rus = rus_vectorization(rus)\n",
    "    return (\n",
    "        {\"english\": eng, \"russian\": rus[:, :-1]}, \n",
    "        # these dict keys will also be the model's Input layers' names\n",
    "        rus[:, 1:]\n",
    "    )\n",
    "    # returns a tuple that will be the model's two inputs\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    eng_texts, rus_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    rus_texts = list(rus_texts)\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, rus_texts))\n",
    "    # # Slicing a tuple of 1D tensors produces tuple elements containing scalar tensors.\n",
    "\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=8)\n",
    "    \n",
    "    dataset = dataset.shuffle(2048).prefetch(16).cache()\n",
    "    # uses in-memory caching to speed up preprocessing.\n",
    "    return dataset\n",
    "\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)\n",
    "test_ds = make_dataset(test_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a5ccdd-3ce4-48d9-9969-7c7980d369fc",
   "metadata": {},
   "source": [
    "## **Architecture**\n",
    "\n",
    "The transformer will be based on [Vaswani et al.'s \"*Attention Is All You Need*\"](https://arxiv.org/abs/1706.03762).\n",
    "\n",
    "![Vaswini et. al](https://www.researchgate.net/publication/339390384/figure/fig1/AS:860759328321536@1582232424168/The-transformer-model-from-Attention-is-all-you-need-Viswani-et-al.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0206ffe4-e8d4-452f-a112-7f7348133d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_dim = 1024\n",
    "num_heads = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b9ffe17-469e-4c8c-988c-ddb4dfdefdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=input_dim, output_dim=output_dim\n",
    "        )\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=output_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0) # does not work on latest tf\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        \n",
    "        embedded_tokens = self.token_embeddings(inputs) \n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "\n",
    "        embeddeding = embedded_tokens + embedded_positions\n",
    "        # combines position information with token representation\n",
    "        \n",
    "        return embeddeding  \n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            'output_dim':self.output_dim,\n",
    "            'sequence_length':self.sequence_length,\n",
    "            'input_dim':self.input_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98616bae-516b-4f5d-9ca6-3a3a11efc0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim # size of token vectors, also the key_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.multi_head_attention = layers.MultiHeadAttention(\n",
    "        # for every attention head:\n",
    "            # Q, K and V all have independent dense connections\n",
    "            # Then, the dense projection's are inputted into attention\n",
    "        # attention outputs of each head are concatenated together\n",
    "            num_heads=num_heads,\n",
    "            key_dim=embed_dim\n",
    "        )\n",
    "        \n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        \n",
    "        self.dense_proj = keras.Sequential([\n",
    "            layers.Dense(dense_dim, activation='relu'),\n",
    "            layers.Dense(embed_dim)\n",
    "        ])\n",
    "        \n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        \n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "        attention_output = self.multi_head_attention(\n",
    "            inputs, inputs, attention_mask=mask\n",
    "        )\n",
    "        before_fc = self.layernorm_1(inputs + attention_output)\n",
    "        after_fc  = self.dense_proj(before_fc)\n",
    "\n",
    "        final_output = self.layernorm_2(before_fc + after_fc)\n",
    "\n",
    "        return final_output\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config  \n",
    "\n",
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "\n",
    "        self.supports_masking = True\n",
    "        \n",
    "        self.multi_head_attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        \n",
    "        self.multi_head_attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "        self.dense_proj  = keras.Sequential([\n",
    "            layers.Dense(self.dense_dim, activation='relu'),\n",
    "            layers.Dense(self.embed_dim)\n",
    "        ])\n",
    "\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs): # necessary to prevent information leakage from future timesteps\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        \n",
    "        mask = tf.linalg.band_part( # returns lower triangle\n",
    "            tf.ones((sequence_length,sequence_length)), -1, 0\n",
    "        )\n",
    "        mask = tf.cast(mask, 'int32')\n",
    "        \n",
    "        mask = tf.tile( # Replicate 100 times along the new axis\n",
    "            mask[tf.newaxis, :, :], \n",
    "            \n",
    "            [batch_size, 1, 1] \n",
    "        )\n",
    "        return mask \n",
    "        # mask has shape: (batch_size, sequence_length, sequence_length)\n",
    "        \n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(\n",
    "                mask[:,tf.newaxis,:], dtype='int32'\n",
    "            )\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "            \n",
    "        multi_head_1_output = self.multi_head_attention_1(\n",
    "            query=inputs, value=inputs, key=inputs, \n",
    "            attention_mask=causal_mask\n",
    "        )\n",
    "\n",
    "        layernorm_1_output = self.layernorm_1(\n",
    "            inputs + multi_head_1_output\n",
    "        )\n",
    "\n",
    "        multi_head_attention_2_output = self.multi_head_attention_2(\n",
    "            query=multi_head_1_output, value=encoder_outputs, key=encoder_outputs, \n",
    "            attention_mask=padding_mask\n",
    "        )\n",
    "\n",
    "        layernorm_2_output = self.layernorm_2(\n",
    "            layernorm_1_output + multi_head_attention_2_output\n",
    "        )\n",
    "\n",
    "        dense_proj_output = self.dense_proj(\n",
    "            layernorm_2_output\n",
    "        )\n",
    "\n",
    "        layernorm_3_output = self.layernorm_3(\n",
    "            layernorm_2_output + dense_proj_output\n",
    "        )\n",
    "        return layernorm_3_output\n",
    "             \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6884aa00-2df9-4f87-8254-cf031a8e7614",
   "metadata": {},
   "source": [
    "### Source sequence (English)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c338601e-b8a7-4290-8b2f-ddb9d8e38c01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "english_input_layer = keras.Input(\n",
    "    shape=(None,), # transformers are shape invariant\n",
    "    dtype=\"int64\", \n",
    "    name=\"english\"\n",
    ")\n",
    "\n",
    "english_embedding = PositionalEmbedding(\n",
    "    sequence_length = sequence_length,\n",
    "    input_dim = vocab_size, \n",
    "    output_dim = embed_dim, \n",
    "    name = 'english_embedding'\n",
    ")(english_input_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337b4a85-b8b1-47e7-b625-361dbc36205b",
   "metadata": {},
   "source": [
    "### Target sequence (russian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed90b8cd-4393-4969-8878-13c46c48d302",
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_input_layer = keras.Input(\n",
    "    shape=(None,), # transformers are shape invariant\n",
    "    dtype=\"int64\", \n",
    "    name = 'russian'\n",
    ")\n",
    "\n",
    "russian_embedding = PositionalEmbedding(\n",
    "    sequence_length = sequence_length,\n",
    "    input_dim = vocab_size, \n",
    "    output_dim = embed_dim, \n",
    "    name = 'russian_embedding'\n",
    ")(russian_input_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28b74c6-92a6-4983-a236-82476e70b19b",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3be99bd1-be03-4f54-be1e-8ee7694ffaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_english = TransformerEncoder(\n",
    "    embed_dim = embed_dim,\n",
    "    dense_dim = dense_dim,\n",
    "    num_heads = num_heads,\n",
    "    name = 'encoder'\n",
    ")(english_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda21e7c-4ed1-460b-b28f-5776007c296d",
   "metadata": {},
   "source": [
    "### Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b88c3d1b-9c05-4984-886b-3f6cf5125036",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = TransformerDecoder(\n",
    "    embed_dim=embed_dim,\n",
    "    dense_dim=dense_dim,\n",
    "    num_heads=num_heads\n",
    ")(russian_embedding, encoder_outputs=encoded_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f859a79-ae8c-44f8-bdaa-a561c33c6bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = layers.Dropout(0.4)(x)\n",
    "output_layer = layers.Dense(vocab_size, activation='softmax', name='output_layer')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90615126-feb5-4ea2-becf-e0d0f773ffa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " english (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " russian (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " english_embedding (PositionalE  (None, None, 256)   3843072     ['english[0][0]']                \n",
      " mbedding)                                                                                        \n",
      "                                                                                                  \n",
      " russian_embedding (PositionalE  (None, None, 256)   3843072     ['russian[0][0]']                \n",
      " mbedding)                                                                                        \n",
      "                                                                                                  \n",
      " encoder (TransformerEncoder)   (None, None, 256)    2630144     ['english_embedding[0][0]']      \n",
      "                                                                                                  \n",
      " transformer_decoder (Transform  (None, None, 256)   4734208     ['russian_embedding[0][0]',      \n",
      " erDecoder)                                                       'encoder[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, None, 256)    0           ['transformer_decoder[0][0]']    \n",
      "                                                                                                  \n",
      " output_layer (Dense)           (None, None, 15000)  3855000     ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18,905,496\n",
      "Trainable params: 18,905,496\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq2seq_transformer = keras.Model(\n",
    "    inputs = [english_input_layer, russian_input_layer],\n",
    "    outputs= output_layer\n",
    ")\n",
    "\n",
    "print(seq2seq_transformer.summary())\n",
    "\n",
    "keras.utils.plot_model(\n",
    "    seq2seq_transformer, show_shapes=True, show_layer_names=True, dpi=80\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75758f9-e8a0-4332-b05d-ea28af823427",
   "metadata": {},
   "source": [
    "## **Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "736cca24-8ecd-4263-ab66-83e99c4f0fec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "1334/1334 [==============================] - 263s 193ms/step - loss: 1.4683 - accuracy: 0.5992 - val_loss: 0.8345 - val_accuracy: 0.7043\n",
      "Epoch 2/32\n",
      "1334/1334 [==============================] - 459s 344ms/step - loss: 0.7909 - accuracy: 0.7113 - val_loss: 0.6691 - val_accuracy: 0.7419\n",
      "Epoch 3/32\n",
      "1334/1334 [==============================] - 480s 360ms/step - loss: 0.6451 - accuracy: 0.7457 - val_loss: 0.6188 - val_accuracy: 0.7561\n",
      "Epoch 4/32\n",
      "1334/1334 [==============================] - 492s 369ms/step - loss: 0.5703 - accuracy: 0.7658 - val_loss: 0.5996 - val_accuracy: 0.7632\n",
      "Epoch 5/32\n",
      "1334/1334 [==============================] - 507s 380ms/step - loss: 0.5190 - accuracy: 0.7807 - val_loss: 0.5858 - val_accuracy: 0.7687\n",
      "Epoch 6/32\n",
      "1334/1334 [==============================] - 493s 370ms/step - loss: 0.4815 - accuracy: 0.7919 - val_loss: 0.5852 - val_accuracy: 0.7712\n",
      "Epoch 7/32\n",
      "1334/1334 [==============================] - 496s 372ms/step - loss: 0.4515 - accuracy: 0.8011 - val_loss: 0.5849 - val_accuracy: 0.7729\n",
      "Epoch 8/32\n",
      "1334/1334 [==============================] - 493s 369ms/step - loss: 0.4255 - accuracy: 0.8095 - val_loss: 0.5827 - val_accuracy: 0.7759\n",
      "Epoch 9/32\n",
      "1334/1334 [==============================] - 495s 371ms/step - loss: 0.4036 - accuracy: 0.8166 - val_loss: 0.5823 - val_accuracy: 0.7763\n",
      "Epoch 10/32\n",
      "1334/1334 [==============================] - 492s 369ms/step - loss: 0.3845 - accuracy: 0.8229 - val_loss: 0.5857 - val_accuracy: 0.7781\n",
      "Epoch 11/32\n",
      "1334/1334 [==============================] - 494s 370ms/step - loss: 0.3685 - accuracy: 0.8282 - val_loss: 0.5899 - val_accuracy: 0.7781\n",
      "Epoch 12/32\n",
      "1334/1334 [==============================] - 516s 387ms/step - loss: 0.3526 - accuracy: 0.8335 - val_loss: 0.5926 - val_accuracy: 0.7792\n",
      "Epoch 13/32\n",
      "1334/1334 [==============================] - 598s 448ms/step - loss: 0.3394 - accuracy: 0.8384 - val_loss: 0.5974 - val_accuracy: 0.7800\n",
      "Epoch 14/32\n",
      "1334/1334 [==============================] - 574s 431ms/step - loss: 0.3272 - accuracy: 0.8426 - val_loss: 0.6089 - val_accuracy: 0.7798\n",
      "Epoch 15/32\n",
      "1334/1334 [==============================] - 495s 371ms/step - loss: 0.3164 - accuracy: 0.8466 - val_loss: 0.6138 - val_accuracy: 0.7791\n",
      "Epoch 16/32\n",
      "1334/1334 [==============================] - 494s 370ms/step - loss: 0.3063 - accuracy: 0.8502 - val_loss: 0.6163 - val_accuracy: 0.7800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21e53414730>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=3,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "seq2seq_transformer.compile(\n",
    "    optimizer=optimizers.Adam(),\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"] # next token accuracy\n",
    ")\n",
    "\n",
    "seq2seq_transformer.fit(\n",
    "    train_ds, \n",
    "    epochs=32, \n",
    "    validation_data=val_ds,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b45d3b7-bb56-4859-ba47-68a8121c4f75",
   "metadata": {},
   "source": [
    "## **Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8db98ac0-1603-4333-b649-1865f6196d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286/286 [==============================] - 46s 160ms/step - loss: 0.5930 - accuracy: 0.7815\n",
      "{'loss': 0.5929856300354004, 'accuracy': 0.7814801335334778}\n"
     ]
    }
   ],
   "source": [
    "print(seq2seq_transformer.evaluate(test_ds, return_dict=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e97fa4-4f34-45f1-b6af-bf533fa57a37",
   "metadata": {},
   "source": [
    "### Examples of translations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a61ebcc4-a3a6-4f8d-97f6-d3197a5c01bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dogs seem happy.\n",
      "[start] Ð¡Ð¾Ð±Ð°ÐºÐ¸ ÐºÐ°Ð¶ÐµÑ‚ÑÑ ÑÑ‡Ð°ÑÑ‚Ð»Ð¸Ð²Ñ‹ [end]\n",
      "\n",
      "Tom spent three decades in prison for a crime he didn't commit.\n",
      "[start] Ð¢Ð¾Ð¼ Ð¿Ð¾Ñ‚Ñ€Ð°Ñ‚Ð¸Ð» Ð² Ñ‚ÑŽÑ€ÑŒÐ¼Ðµ Ñ‚Ñ€Ð¸ Ð³Ð¾Ð´Ð° [UNK] Ð² Ð½ÐµÐ²Ð¸Ð½Ð¾Ð²Ð½Ð¾ÑÑ‚Ð¸ [end]\n",
      "\n",
      "It's not that small.\n",
      "[start] Ð­Ñ‚Ð¾ Ð½Ðµ Ñ‚Ð°Ðº ÑƒÐ¶ Ð¸ Ð¼Ð°Ð»ÐµÐ½ÑŒÐºÐ¸Ð¹ [end]\n",
      "\n",
      "I hope you don't miss your flight.\n",
      "[start] ÐÐ°Ð´ÐµÑŽÑÑŒ Ñ‚Ñ‹ Ð½Ðµ Ð¾Ð¿Ð¾Ð·Ð´Ð°ÐµÑˆÑŒ Ð½Ð° ÑÐ°Ð¼Ð¾Ð»Ñ‘Ñ‚ [end]\n",
      "\n",
      "The door is closing.\n",
      "[start] Ð”Ð²ÐµÑ€ÑŒ Ð·Ð°ÐºÑ€Ñ‹Ð²Ð°ÐµÑ‚ÑÑ [end]\n",
      "\n",
      "Was it a lie when you said you loved me?\n",
      "[start] Ð­Ñ‚Ð¾ Ð±Ñ‹Ð»Ð¾ [UNK] ÐºÐ¾Ð³Ð´Ð° Ñ‚Ñ‹ ÑÐºÐ°Ð·Ð°Ð» Ð¼Ð½Ðµ [UNK] [end]\n",
      "\n",
      "Do you know how to tie a tie?\n",
      "[start] Ð’Ñ‹ ÑƒÐ¼ÐµÐµÑ‚Ðµ Ð·Ð°Ð²ÑÐ·Ñ‹Ð²Ð°Ñ‚ÑŒ [UNK] [end]\n",
      "\n",
      "Your pencils need to be sharpened.\n",
      "[start] Ð¢Ð²Ð¾Ð¸ ÐºÐ°Ñ€Ð°Ð½Ð´Ð°ÑˆÐ¸ Ð½ÑƒÐ¶Ð½Ð¾ [UNK] [end]\n",
      "\n",
      "Tom remained in Boston for a few days.\n",
      "[start] Ð¢Ð¾Ð¼ Ð¾ÑÑ‚Ð°Ð»ÑÑ Ð² Ð‘Ð¾ÑÑ‚Ð¾Ð½Ðµ Ð½Ð° Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¾ Ð´Ð½ÐµÐ¹ [end]\n",
      "\n",
      "I thought you'd seen this movie.\n",
      "[start] Ð¯ Ð´ÑƒÐ¼Ð°Ð» Ñ‚Ñ‹ Ð²Ð¸Ð´ÐµÐ» ÑÑ‚Ð¾Ñ‚ Ñ„Ð¸Ð»ÑŒÐ¼ [end]\n",
      "\n",
      "I feel like someone is watching me.\n",
      "[start] Ð¯ Ñ‡ÑƒÐ²ÑÑ‚Ð²ÑƒÑŽ Ñ‡Ñ‚Ð¾ Ð·Ð° Ð¼Ð½Ð¾Ð¹ ÐºÑ‚Ð¾Ñ‚Ð¾ Ð½Ð°Ð±Ð»ÑŽÐ´Ð°ÐµÑ‚ [end]\n",
      "\n",
      "It was incredibly dangerous.\n",
      "[start] Ð­Ñ‚Ð¾ Ð±Ñ‹Ð»Ð¾ Ð½ÐµÐ²ÐµÑ€Ð¾ÑÑ‚Ð½Ð¾ Ð¾Ð¿Ð°ÑÐ½Ð¾ [end]\n",
      "\n",
      "I told Tom that I'd made a mistake.\n",
      "[start] Ð¯ ÑÐºÐ°Ð·Ð°Ð» Ð¢Ð¾Ð¼Ñƒ Ñ‡Ñ‚Ð¾ ÑÐ´ÐµÐ»Ð°Ð» Ð¾ÑˆÐ¸Ð±ÐºÑƒ [end]\n",
      "\n",
      "Tom used to drive a bus.\n",
      "[start] Ð¢Ð¾Ð¼ Ñ€Ð°Ð½ÑŒÑˆÐµ ÑÐ¸Ð´ÐµÐ» Ð·Ð° Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÐµÐ¼ Ð°Ð²Ñ‚Ð¾Ð±ÑƒÑÐ° [end]\n",
      "\n",
      "Tom didn't work alone.\n",
      "[start] Ð¢Ð¾Ð¼ Ð½Ðµ Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ð» Ð¾Ð´Ð¸Ð½ [end]\n",
      "\n",
      "Doing that is a waste of your time.\n",
      "[start] Ð­Ñ‚Ð¾ [UNK] ÑÑ‚Ð¾ Ñ‚Ñ€Ð°Ñ‚Ð° Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ Ð²Ð°ÑˆÐµÐ³Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸ [end]\n",
      "\n",
      "I thought that Tom and Mary were already married.\n",
      "[start] Ð¯ Ð´ÑƒÐ¼Ð°Ð» Ð¢Ð¾Ð¼ Ñ ÐœÑÑ€Ð¸ ÑƒÐ¶Ðµ Ð¶ÐµÐ½Ð°Ñ‚Ñ‹ [end]\n",
      "\n",
      "The Rhine flows between France and Germany.\n",
      "[start] [UNK] Ñ‚ÐµÑ‡Ñ‘Ñ‚ Ð¼ÐµÐ¶Ð´Ñƒ [UNK] Ð¸ [UNK] [end]\n",
      "\n",
      "What's your favorite sport to watch?\n",
      "[start] ÐšÐ°ÐºÐ¸Ðµ Ñƒ Ñ‚ÐµÐ±Ñ Ð»ÑŽÐ±Ð¸Ð¼Ñ‹Ð¹ Ð²Ð¸Ð´ ÑÐ¿Ð¾Ñ€Ñ‚Ð° [UNK] [end]\n",
      "\n",
      "That isn't what I'm talking about.\n",
      "[start] Ð¯ Ð½Ðµ Ð¾Ð± ÑÑ‚Ð¾Ð¼ Ð³Ð¾Ð²Ð¾Ñ€ÑŽ [end]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rus_index_lookup = dict(enumerate(rus_vectorization.get_vocabulary()))\n",
    "\n",
    "def decode_sequence(\n",
    "    input_sentence, \n",
    "    max_decoded_sentence_length = 12\n",
    "):\n",
    "    tokenized_input_sentence = eng_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    \n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = rus_vectorization([decoded_sentence])\n",
    "        \n",
    "        predicted_next_token = seq2seq_transformer.predict(\n",
    "            [tokenized_input_sentence, tokenized_target_sentence[:,:-1]], \n",
    "            verbose=0\n",
    "        )\n",
    "        \n",
    "        sampled_token_index = np.argmax(predicted_next_token[0, i, :])\n",
    "        sampled_token = rus_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "for _ in range(20):\n",
    "    random_english_sentence_index = random.randint(0, num_val_samples - 1)\n",
    "    input_sentence = test_pairs[random_english_sentence_index][0]\n",
    "    \n",
    "    print(input_sentence)\n",
    "    print(decode_sequence(input_sentence), end='\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e522e312-bf08-4714-9afa-e3c6aee18064",
   "metadata": {},
   "source": [
    "[UNK] refers to a word that was not tokenised because it did not appear frequently enough in the training corpus. The `vocab_size` hyperparameter from early controls this limit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
